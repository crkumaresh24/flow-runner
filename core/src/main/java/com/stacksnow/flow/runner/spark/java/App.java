/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package com.stacksnow.flow.runner.spark.java;

import com.google.gson.Gson;
import com.google.gson.reflect.TypeToken;
import com.stacksnow.flow.runner.spark.java.cli.ITask;
import com.stacksnow.flow.runner.spark.java.contextmanagers.SparkFlowContext;
import com.stacksnow.flow.runner.spark.java.model.DAG;
import com.stacksnow.flow.runner.spark.java.model.Edge;
import com.stacksnow.flow.runner.spark.java.model.Node;
import com.stacksnow.flow.runner.spark.java.model.RunnerEntry;
import org.apache.commons.io.IOUtils;
import org.jgrapht.experimental.dag.DirectedAcyclicGraph;
import org.jgrapht.traverse.TopologicalOrderIterator;

import java.lang.reflect.Type;
import java.net.URL;
import java.nio.charset.StandardCharsets;
import java.util.Map;
import java.util.Set;

public class App {
    public DirectedAcyclicGraph startDAG(Map<String, RunnerEntry> runnerEntries, DAG dag) throws Exception {
        DirectedAcyclicGraph<Node, Edge> graph = new DirectedAcyclicGraph(Edge.class);
        dag.getNodes().forEach(node -> {
            if (null != node.getAttributes()) {
                graph.addVertex(node);
                node.getAttributes().setStatusId(2);
            }
        });
        dag.getEdges().forEach(edge -> {
            Node source = dag.getNodes().stream().filter(node -> node.getKey().equalsIgnoreCase(edge.getSource())).findFirst().orElseThrow(RuntimeException::new);
            Node target = dag.getNodes().stream().filter(node -> node.getKey().equalsIgnoreCase(edge.getTarget())).findFirst().orElseThrow(RuntimeException::new);
            graph.addEdge(source, target, new Edge(edge.getKey(), source.getKey(), target.getKey()));
        });
        TopologicalOrderIterator<Node, Edge> iterator = new TopologicalOrderIterator<>(graph);
        SparkFlowContext flowContext = new SparkFlowContext();
        while (iterator.hasNext()) {
            Node node = iterator.next();
            String type = node.getAttributes().getType();
            if (null == runnerEntries.get(type)) {
                throw new RuntimeException("runner not found for " + node.getAttributes().getType());
            }
            Class<? extends ITask> taskClass = (Class<? extends ITask>) Class.forName(runnerEntries.get(type).getRunner());
            Set<Edge> incomingEdges = graph.incomingEdgesOf(node);
            String[] ins = incomingEdges.stream().map(Edge::getSource).toArray(String[]::new);
            if (ins.length > 0) {
                System.out.println(ins[0]);
            }
            flowContext.putResponse(node.getKey(), taskClass.newInstance().execute(flowContext, ins, node.getAttributes().getRequest()));
        }
        return graph;
    }

    private void start(String runnersListUrl, String planFileUrl) throws Exception {
        String runnersList = IOUtils.toString(new URL(runnersListUrl), StandardCharsets.UTF_8);
        String dagString = IOUtils.toString(new URL(planFileUrl), StandardCharsets.UTF_8);
        Gson gson = new Gson();
        DAG dag = gson.fromJson(dagString, DAG.class);
        Type runnerType = new TypeToken<Map<String, RunnerEntry>>() {
        }.getType();
        Map<String, RunnerEntry> runnerEntries = gson.fromJson(runnersList, runnerType);
        startDAG(runnerEntries, dag);
    }

    public static void main(String[] args) throws Exception {
        // args = new String[]{"file:///Users/kchenniappanramak/Downloads/flowPlan.json", "file:///Users/kchenniappanramak/Documents/github/flow-runner-spark-cluster-java/app/src/main/resources/runnerList.json"};
        new App().start(args[0], args[1]);
    }
}
